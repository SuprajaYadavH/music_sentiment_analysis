{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "0af62de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy is already initialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn = -1)\n",
    "library('stringr')\n",
    "library('hunspell')\n",
    "library('ds4psy')\n",
    "library('glue')\n",
    "library('spacyr')\n",
    "library('tm')\n",
    "library('dplyr',  warn.conflicts = FALSE)\n",
    "library('parsedate')\n",
    "library(\"tokenizers\", warn.conflicts = FALSE)\n",
    "\n",
    "# replacing contractions with full forms\n",
    "library('textclean')\n",
    "library('caret')\n",
    "library(\"e1071\")\n",
    "\n",
    "# initializing spacyr\n",
    "spacy_initialize(model = 'en_core_web_sm', virtualenv  = \"/Users/yobahbertrandyonkou/spacyenv/\")\n",
    "\n",
    "# importing model\n",
    "msa_model = readRDS(\"../Models/msa_model_81_lyrics_and_sentiments_only.rda\")\n",
    "\n",
    "# loading corpus\n",
    "angry_corpus = readRDS(\"./angry_corpus.rda\")\n",
    "sad_corpus = readRDS(\"./sad_corpus.rda\")\n",
    "happy_corpus = readRDS(\"./happy_corpus.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "7bd39c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classify_lyrics = function(lyrics){\n",
    "    # replacing ’ with '\n",
    "    test_lyrics = str_replace_all(test_lyrics, \"’\", \"\\'\")\n",
    "\n",
    "    # converting lyrics to lower case\n",
    "    lyrics = tolower(lyrics)\n",
    "\n",
    "    # removing lyrics divisions\n",
    "    lyrics = str_replace_all(\n",
    "            string=lyrics, \n",
    "            pattern=r\"(\\[(.*?)\\])\", \n",
    "            replacement = \" \"\n",
    "        )\n",
    "\n",
    "    # typo correction\n",
    "    bad.words = hunspell(lyrics)\n",
    "\n",
    "    # splitting bad words to a list of words\n",
    "    bad.words = text_to_words(bad.words[1])\n",
    "\n",
    "    # removing duplicates\n",
    "    bad.words = unique(bad.words)\n",
    "\n",
    "    # getting suggestions\n",
    "    suggested.words = unlist(lapply(hunspell_suggest(unique(unlist(bad.words))), function(words) words[1]))\n",
    "\n",
    "    # replacing bad words with suggestions\n",
    "    new_lyrics = \"\"\n",
    "    for (index in 1:length(bad.words)){\n",
    "        new_lyrics = str_replace_all(\n",
    "            string = lyrics, \n",
    "            pattern = glue(r\"(\\b{bad.words[index]}\\b)\"), \n",
    "            replacement = suggested.words[index]\n",
    "        )\n",
    "        lyrics = new_lyrics\n",
    "    }\n",
    "    lyrics = tolower(lyrics)\n",
    "\n",
    "    # replacing all contractions with their full forms\n",
    "    lyrics = replace_contraction(lyrics)\n",
    "\n",
    "    lyrics = replace_internet_slang(lyrics)\n",
    "    lyrics = str_replace_all(lyrics, r\"(\\_?\\-)\", \" \")\n",
    "    lyrics = str_replace_all(lyrics, r\"(\\d)\", \" \")\n",
    "    lyrics = str_replace_all(\n",
    "            string=lyrics, \n",
    "            pattern=r\"(\\s+)\", \n",
    "            replacement = \" \"\n",
    "        )\n",
    "\n",
    "    # pos tagging, lematization\n",
    "    # Not using transform here because it combines every thing into one long string\n",
    "    important = c()\n",
    "    lemmatized_lyrics = c()\n",
    "    features = filter(\n",
    "        spacy_parse(lyrics, tag=TRUE, pos=TRUE), \n",
    "        !(pos %in% important) & (entity == \"\")\n",
    "    )\n",
    "\n",
    "    lemmatized_lyrics = append(\n",
    "        lemmatized_lyrics, \n",
    "        paste(features$lemma, collapse = ' ')\n",
    "    )\n",
    "    lyrics = lemmatized_lyrics\n",
    "\n",
    "    # fetching english stopwords\n",
    "    stopwords.list = stopwords(kind = \"en\")\n",
    "\n",
    "    # removing contractions from stop words because lyrics does not have stop words\n",
    "    stopwords.cleaned = tolower(replace_contraction(stopwords.list))\n",
    "\n",
    "    for (stopword in stopwords.cleaned){\n",
    "        lyrics = str_remove_all(tolower(lyrics), glue(r\"(\\b\\s?{stopword}\\b)\"))\n",
    "    }\n",
    "\n",
    "    lyrics = tolower(removePunctuation(lyrics))\n",
    "\n",
    "    lyrics = str_replace_all(\n",
    "            string=lyrics, \n",
    "            pattern=r\"(\\s+)\", \n",
    "            replacement = \" \"\n",
    "        )\n",
    "\n",
    "    lyrics_corpus = Corpus(VectorSource(lyrics))\n",
    "\n",
    "    # creating a document term matrix from lyrics corpus\n",
    "    get_lyrics_document_term_matrix = function(lyrics_corpus){\n",
    "        return (\n",
    "            removeSparseTerms(\n",
    "                DocumentTermMatrix(lyrics_corpus, control = list(\n",
    "                    weighting=function(x) weightTfIdf(x, normalize = TRUE)\n",
    "                )), 0.95\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "\n",
    "    lyric_with_angry_corpus = Corpus(VectorSource(c(lyrics_corpus$content, angry_corpus$content)))\n",
    "    dtm_with_angry = get_lyrics_document_term_matrix(lyric_with_angry_corpus)\n",
    "    lyric_with_happy_corpus = Corpus(VectorSource(c(lyrics_corpus$content, happy_corpus$content)))\n",
    "    dtm_with_happy = get_lyrics_document_term_matrix(lyric_with_happy_corpus)\n",
    "    lyric_with_sad_corpus = Corpus(VectorSource(c(lyrics_corpus$content, sad_corpus$content)))\n",
    "    dtm_with_sad = get_lyrics_document_term_matrix(lyric_with_sad_corpus)\n",
    "\n",
    "    # converting dtm to matrix\n",
    "    get_lyrics_dtm_matrix = function(lyrics_document_term_matrix) as.matrix(lyrics_document_term_matrix[1 , ])\n",
    "\n",
    "    with_happy = get_lyrics_dtm_matrix(dtm_with_happy)\n",
    "    with_sad = get_lyrics_dtm_matrix(dtm_with_sad)\n",
    "    with_angry = get_lyrics_dtm_matrix(dtm_with_angry)\n",
    "\n",
    "    # predictions\n",
    "    pred_for_happy = predict(msa_model, data.frame(with_happy), type = \"raw\")\n",
    "    pred_for_angry = predict(msa_model, data.frame(with_angry), type = \"raw\")\n",
    "    pred_for_sad = predict(msa_model, data.frame(with_sad), type = \"raw\")\n",
    "\n",
    "    sum_of_probs = pred_for_angry + pred_for_happy + pred_for_sad\n",
    "    probs = transform(sum_of_probs, \n",
    "              angry=(angry - min(sum_of_probs))/max(sum_of_probs) - min(sum_of_probs),\n",
    "              sad=(sad - min(sum_of_probs))/max(sum_of_probs) - min(sum_of_probs),\n",
    "              happy=(happy - min(sum_of_probs))/max(sum_of_probs) - min(sum_of_probs)\n",
    "             )\n",
    "\n",
    "    result = array(pred_for_angry + pred_for_happy + pred_for_sad)\n",
    "    labels = array(names(data.frame(pred_for_angry + pred_for_happy + pred_for_sad)))\n",
    "    index = 1\n",
    "    max = 1\n",
    "    for (value in result){\n",
    "        if(value > result[max]){\n",
    "            max = index\n",
    "        }\n",
    "        index = index + 1\n",
    "    }\n",
    "    print(probs)\n",
    "    return (labels[max])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "c62568dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "test_data = read.csv(\"../Datasets/happy_test.csv\")\n",
    "lyrics_list = unlist(test_data['raw_lyrics'])[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "dc5e3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  angry happy          sad\n",
      "1   0.5     1 2.861329e-39\n"
     ]
    }
   ],
   "source": [
    "results = c()\n",
    "for(lyrics in lyrics_list){\n",
    "    results = append(results, classify_lyrics(lyrics))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "0c0ccebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results\n",
       "sad \n",
       "  1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "8711006c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "95"
      ],
      "text/latex": [
       "95"
      ],
      "text/markdown": [
       "95"
      ],
      "text/plain": [
       "[1] 95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "bf5f3b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34.6534653465347"
      ],
      "text/latex": [
       "34.6534653465347"
      ],
      "text/markdown": [
       "34.6534653465347"
      ],
      "text/plain": [
       "[1] 34.65347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(35/length(results)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f96211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
